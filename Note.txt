Transient State:
When an object of the Student class is created but not yet saved in the database.
The ID of this object is null in this state.
The object exists only in Java memory.
When save() is called:
First, it checks whether the object is new or has been saved before.
Criteria for detection: Is ID == null?
If yes → the object is new → uses EntityManager.persist().
If no → the object exists → uses EntityManager.merge().
What happens after persist()?
An INSERT is performed in the database.
The object changes state from transient to persistent.
An ID is created by the database for the object (e.g. 1).
Detached State:
After the transaction is committed and the EntityManager is closed, the object is no longer managed.
The object enters the detached state.
Always work only with the returned object after using save(). Depending on the circumstances, it may have been merged and a new object may have been returned.

Objective: Update a Student in the database using the save method
Step 1: Create and save a new entity
Here, a new object of the Student class is created and saved using save.
Behind the scenes, EntityManager.persist() is called.
The object is placed in a detached state; that is, it is detached from the context but its information is stored in the database.
Step 2: Update the entity information
What happens when a Detached entity is saved with save()?
When you have previously saved an entity (for example, Student) in the database and now keep it in Java memory as detached (i.e. outside Hibernates control) and want to save it again using the save() method (which uses EntityManager.merge() behind the scenes), Hibernate goes through the following steps:
1. Checking for the existence of an entity in the Persistence Context
Hibernate first checks:
"Is an entity with the same ID (e.g. id = 1) already managed in memory (the Persistence Context or 1st-level cache)?"
If there isn't one (which is usually the case):
Hibernate sends a SELECT to the database to read the record for that ID.
Result: Hibernate now loads a copy of Student with id = 1 from the database and puts it in persistent state.
Hibernate then copies the data from your detached entity to the newly loaded entity.
In other words: the state of the detached object is transferred to the persistent object.
2. Dirty Checking
Hibernate now checks whether the values of the persistent entity fields have changed since the initial load after copying the data.
If there is a change (such as changing the name Alisa to Alissa):
Hibernate detects that the entity has become "dirty", meaning it needs to be updated.
Hibernate then issues an UPDATE
3. Returning the new entity to the client
After executing merge():
Hibernate removes the persistent object from the context (i.e., detaches it).
The new version of that entity (which now has new information such as name = "Alissa") is returned as the output of the save() method.

Detached Entity (id=1, name="Alissa")   →  save() →  merge() →
→ SELECT student WHERE id = 1 →
→ Load persistent entity from DB →
→ Copy state from detached → persistent →
→ Dirty Checking detects change →
→ UPDATE student SET name='Alissa' WHERE id=1 →
→ Return new detached entity (updated)

Deleting a Detached Object
When delete(returnStudent) is executed, Hibernate faces three problems:
Problem 1: Does this entity actually exist in the database?
Hibernate needs to check whether the record actually exists.
Hibernate first uses EntityManager.find().
This causes a SELECT to be executed to find the record in the database.
Problem 2: The object cannot be deleted because it is Detached!
Hibernate can only delete Entities that are in Persistent state.
If it tries to delete the Detached object directly, we get an Exception:
IllegalArgumentException: Removing a detached instance
Solution: Using merge()
What does Hibernate do?
First it uses merge(returnStudent).
If an Entity with the same ID exists in the Context, it uses it.
If not, it SELECTs again and loads it from the database.
The returnStudent data is copied to that new Entity.
As a result, Hibernate has a new Entity in the Persistent state.
The final step: the actual deletion
Now that we have an Entity in the Persistent state:
Hibernate removes it using EntityManager.remove() .
This executes a DELETE statement in the database.
Important:
The returnStudent object is not deleted.
Instead, Hibernate:
Creates a new copy of it,
Merges the data,
And deletes the new copy.
After the deletion, returnStudent is still in the Detached state!

Are there always two SELECTs?
No. If the following conditions are met, Hibernate may just do a SELECT or even delete without a SELECT:
Case 1: If the same entity is already in context (e.g. still in context after findById())
In that case Hibernate uses the same instance.
No need for merge() and new SELECT.
Just remove() and finally a DELETE.
Case 2: If the entity is in Persistent state (e.g. still alive in the same transaction)
Hibernate directly does remove(), without SELECT

What is Spring Data Commons?
It provides a common foundation for all Spring Data projects, whether for relational or non-relational (NoSQL) databases.
This project defines the main and public Repository interfaces such as Repository, CrudRepository, and PagingAndSortingRepository.

Spring Data JPA and Spring Data Commons Relationship
Spring Data JPA is built on top of Spring Data Commons.
JpaRepository, which is used in JPA projects, itself inherits from PagingAndSortingRepository, which belongs to Spring Data Commons.
Therefore, in addition to CRUD methods, it is possible to use methods related to pagination and sorting.
You can also use CrudRepository or PagingAndSortingRepository directly if you do not need all the features of JpaRepository.

Spring Data MongoDB and Spring Data Commons Relationship
Spring Data MongoDB is also built on Spring Data Commons, similar to JPA.
MongoRepository in Spring Data MongoDB is similar to JpaRepository but is specific to working with MongoDB databases.
This makes working with MongoDB and JPA very similar in terms of API and makes it easier to switch between them.
Spring Data's overall philosophy
Spring Data aims to provide a unified and database-independent programming model.
This allows developers to migrate from relational databases to NoSQL and vice versa without much change in the code.

Creating a custom Repository with custom methods from different interfaces (such as CrudRepository and JpaRepository)
We want to create a Repository called MyCustomRepository that has only these 3 methods
How do we create a Repository that has only these three methods?
MyCustomRepository should only inherit from the base Repository (marker interface) and then define these three custom methods inside itself.
Spring Data JPA creates an implementation for this Repository dynamically (Dynamic Proxy) at runtime that implements those methods.
Why might we want to have only three methods? Why not use the full JpaRepository?
You might not want all the methods to be available to developers.
For example, you don't want to have deleteById because you use soft delete.
You don't want to give the most complete access to specific modules or external APIs.

Named Queries
If you want to define a query in the Entity itself:
Named JPQL Query in the Student entity:

@NamedQuery(
  name = "Student.findByName",
  query = "SELECT s FROM Student s WHERE s.name = :name"
)

Named Native SQL Query:

@NamedNativeQuery(
  name = "Student.findByNameEndingWith",
  query = "SELECT * FROM student WHERE name LIKE %:pattern",
  resultClass = Student.class
)

By default, JUnit 5 creates a new object of the test class for each test method. That is, if your test class has 3 methods, 3 instances of the class will be created.
@TestInstance(TestInstance.Lifecycle.PER_METHOD)

If you want only one object of the test class to be created to execute all test methods, you should write this annotation:
@TestInstance(TestInstance.Lifecycle.PER_CLASS)
The test class is instantiated only once.
You can use non-static fields in the @BeforeAll and @AfterAll methods.

Suppose you want to use a Repository (say StudentRepository) initialized with @Autowired.
In the default case (PER_METHOD):
Because @BeforeAll must be static, you cannot use studentRepository (because static methods do not have access to non-static fields).
But with PER_CLASS:
The @BeforeAll method can be non-static, so you have access to the studentRepository field.
This means you can prepare the database with Repository before running the tests.

If the Repository method is annotated with @Query, the same query will be executed. This has the highest priority.
If @Query is not present, Spring Data JPA checks whether a Named Query with the same name is defined (for example, in the entity class with @NamedQuery). If so, it will be executed.
If neither @Query nor Named Query is defined, then Spring Data JPA attempts to automatically generate and execute a query based on the method name (i.e., a Derived Query).

Query by Example (QBE) is a way in which:
Instead of writing a manual query (like findByLastNameAndLevel)
You create an object of the class you want and pass it to JPA
JPA will search the database for records that are similar to that object
This object is called: "Probe" (like an example that we need to search for)

Step 1: Create a Probe
Suppose you want to find all users who:
lastName = "Smith"
level = 2

User probe = new User();
probe.setLastName("Smith");
probe.setLevel(2);

Step 2: Create an Example
Example<User> example = Example.of(probe);

Step 3: Search with Repository
List<User> result = userRepository.findAll(example);

This line says:
Go get all users with lastName = "Smith" and level = 2.

The problem occurs when you use primitive fields
For example, if you just write:
User probe = new User();
probe.setLastName("Smith");
You think level will be ignored, but no! You are wrong.
Why?
Because level is an int and the default value of int is 0.
It is actually telling JPA:
Look for lastName = "Smith" and level = 0!
And since there is no user with level = 0 in our database, the result is: empty list.
What is the solution? Using ExampleMatcher
We are telling JPA:
Please ignore level, even though it has a default value!

ExampleMatcher matcher = ExampleMatcher.matching()
.withIgnorePaths("level"); // Ignore level field
Example<User> example = Example.of(probe, matcher);
List<User> result = userRepository.findAll(example);

Ignore a specific field .withIgnorePaths("level")
Ignore case .withIgnoreCase()
Match first, middle, or last name? .withMatcher("firstName", startsWith()), contains(), endsWith()

A transaction is a set of operations that are executed as an atomic unit. Either all of those operations are successful, or none of them are successful and all are rolled back to the previous state.
Suppose you have a ticket booking application. When a user makes a ticket reservation, a seat must first be assigned to him and then the payment must be made. If the payment fails, the seat must not be reserved for him. This is possible using a "transaction".
Commit:
This means that all the operations within the transaction have been completed successfully and now the database must save those changes and make them visible to other users.
Rollback:
This means that an error has occurred and the changes made must be rolled back to the previous state; no trace of that operation remains in the database.

Basic properties of a transaction (ACID)
1. Atomicity
All operations in a transaction must be completed completely or none of them.
Example:
Suppose you are transferring money from your bank account to someone else's account.
The two main operations are:
Money decreases in your account
Money increases in the other party's account
If only one of them happens (for example, money decreases in your account but does not reach the other party's account), it is a disaster!
Atomicity guarantees that either both happen, or neither happens.

2. Consistency
The database must remain in a valid state before and after the transaction.

Example:
Suppose there is a rule in the database that the account balance should never become negative.
If this rule is violated during the transaction, the entire transaction must be canceled.
Consistency means that after the transaction is executed, the data is still consistent with the rules of the system.

3. Isolation
Transactions should not affect each other or have incomplete results.
Example:
Suppose two people are simultaneously reserving a specific seat in a ticketing system.
If the transactions are not isolated, both people could end up buying the same seat!
Isolation prevents this from happening. Each transaction is executed as if in its own space.

4. Durability
Once a transaction is successfully committed, the data should persist forever, even if the system crashes or loses power.
Example:
If a user purchases a ticket and the system shuts down after a few moments, the ticket should still be recorded in the database.
Durability means that the database retains that information as soon as the transaction is committed.

One of the first things that comes to mind when talking about getting a database connection is that it is a resource-intensive process.
If your application does not use a connection pool, every time a database operation is performed, that operation will be relatively slow and will not be suitable for your application in terms of performance.
Here’s how it works: when a client sends a request to perform an operation on the database (e.g., register a ticket), if your Spring application is not configured to use a connection pool, behind the scenes, the application opens a new connection to the database; this is relatively time-consuming.
And when the database operation is finished processing, the server has to close this connection before the response can be returned to the client; this is also slow.
And only after the connection is closed, the response is returned to the client.
So if your application does not use a connection pool, every database operation will be very slow; Because opening and closing a connection are two very time-consuming and expensive processes.

In production environments, you absolutely do not want to have an application that does not use a connection pool.
And when your application is properly configured to use a connection pool, when the server starts, it automatically pre-empts several connections to the database.
As a result, you have a pool of connections ready to be used by clients for database operations.
Now, if we have the same request as before – say, saving a ticket – this time, instead of opening a new connection, the server just borrows one of the free connections in the pool.
A connection that is not currently busy responding to another request.
Then, it hands your request over to that same connection to perform the ticket registration operation or any other database operation.
So this time, with the connection pool, the ticket registration operation will not be as slow as before; Because we didn’t need to open a new connection.
We just had to borrow an existing one.
So, this time the operation is performed significantly faster.
And when that connection is done with the database operation (in our example, registering a ticket), the server doesn’t close that connection.
Instead, it simply returns it to the connection pool to be used to respond to other client requests.
That is, the connection that was borrowed from the pool is not closed, but released and returned to the pool and remains open.
This will make your database operations even faster, because as we said, closing a connection is also a slow process.

Spring Boot uses a connection pooling library called HikariCP by default.
And now when you mark a method in a service with the @Transactional annotation, if you use Resource-local (i.e. you only have one datasource), Hibernate immediately acquires a database connection at the very beginning of the transaction, i.e. immediately after the transactional method is called.
This connection is for a JDBC transaction that is acquired at the beginning of the method execution – even before any actual operations are performed on the database.
This is not good, because acquiring a connection and not using it can hurt the performance of your application.
You should acquire a connection only when you are actually going to perform a database operation, not at the beginning of the method.
For example, let's say we have a method in a service that is annotated with @Transactional.
When this method is called from the client, a transaction is immediately started with the EntityManager.
And what we are going to examine in this session is that at this very moment, even before doing anything, Hibernate gets a connection to the database.
Suppose in line 17 we do something that takes time, but does not require a database connection.
For example, we simulate a task that takes 40 seconds using Thread.sleep(40000).
If you look at the console log at this moment, you will see that even in the case where line 17 does not require any database, HikariCP has an active connection.
That is, out of 10 connections in the connection pool, one of them is active, while we do not need it - which is not good from a performance point of view.
You should get the connection exactly when you really need it - for example, in line 19 when we find a ticket from the database - and not earlier.
Here you may ask:
Why does this happen?
Why is the database connection taken right at the beginning of the method and why is this process not delayed until line 19 when the database operation is performed?
The answer is that in resource-local JPA transactions, the database connection is taken immediately.
Because Hibernate needs to check the auto-commit status of the underlying JDBC connection; and if it is enabled, disable it.
That is why the connection must be taken at the beginning of the method; because without this, the transaction cannot be managed as an atomic unit.

That is, each database operation is stored immediately, independently, and permanently; each operation has its own transaction.
For example, if a ticket reservation requires two operations—first assigning a seat, second receiving the payment—in auto-commit mode, each of these operations has a separate transaction.
And this is not what we want at all.
We want either both to happen, or neither (atomicity).
And this happens if auto-commit is disabled.
Hibernate does exactly the same thing: it disables auto-commit at the beginning of the method, and to do this, it has to acquire a connection.
So, the solution to this problem is to postpone the process of acquiring the connection until the first database operation is reached (lazy connection acquisition).
And this can be done very easily, just set the following two properties in the application.properties file:

spring.datasource.hikari.auto-commit=false
hibernate.connection.provider_disables_autocommit=true

These two properties make Hibernate disable auto-commit by itself, instead of connecting at the beginning of the method to disable auto-commit.
As a result, Hibernate no longer needs to connect at the beginning of the method.
Rather, this connection is only taken when the actual operation on the database begins.
The first property is related to Hikari, and the second is related to Hibernate.
Be sure to enable both, because just one is not enough.
To see the HikariCP logs, you can also set the corresponding log level to trace:

logging.level.com.zaxxer.hikari=TRACE

With this, the connection pool status will be logged to the console every 30 seconds.

Let's say we have an entity called Guide that has an ID, a staff ID, a name, and a salary.
This entity is mapped to the guide table, which currently contains two guides.
We also have a GuideRepository that we use to store this entity. This repository inherits from JpaRepository.

Now the question is:
What will be the result of executing this method written here?
In this service method (on line 18), we first try to find the guide with the ID 1. Then, in the next line, we increase his salary from 1000 to 2500.

This method is marked with the @Transactional annotation, which means it runs in a transaction context;
In such a way that when the method starts executing, a transaction is started and at the end of the method, the transaction is committed or rolled back in case of an error.

In your opinion, can this method change the permissions of the user with ID 1 to 2500?
The answer is yes; the permissions of this user will be changed to 2500.
Why? Because by default, Spring transactions work in read/write mode, and in this mode, dirty checking is automatically performed when the transaction is committed.
In this process, Hibernate checks whether any data has changed, and if so, issues an SQL update statement that updates the permissions in the database to 2500.

The first thing we need to know is that the default value of the readOnly attribute in the @Transactional annotation is false, which means that the transaction is executed in read/write mode.
In this case, automatic dirty checking is performed on commit.

Like this:
When the select statement is executed on line 18 to get the Guide with ID 1, in addition to receiving a Guide object, a snapshot or loaded state of the initial state of that object is also maintained.
This snapshot is used by Hibernate during dirty checking to find out if anything has changed in the object.
During a read/write transaction, the loaded object is managed in the persistence context by the EntityManager.
That is why dirty checking can be performed.
If the state of the object was not managed, dirty checking would not be performed (which happens in read-only transactions).

When we get to line 19 and change the permissions to 2500, this change is recorded in memory (Java memory).
When committing the transaction, Hibernate performs dirty checking:
It compares the current state of the object with the original snapshot.
If it sees a difference (here the permissions have changed from 1000 to 2500), it issues an update command to bring the database into line with the new state.
This will change the permissions of the guide with ID 1 in the guide table to 2500.

These snapshots consume memory.
Dirty checking can be time-consuming, as Hibernate has to check all the objects in the persistence context.
So if you put unnecessary objects into the persistence context, it will cause a performance degradation of the application.
So always try to load only the data that you intend to change in read/write transactions.

Now about read-only transactions
In the second scenario, we do the same thing (load the directory with ID 1 and change the permissions to 2500), but this time our method has @Transactional(readOnly = true).
What happens in this case?
Answer:
This time the permissions are not changed to 2500.
Why?
Because in a read-only transaction,
dirty checking is not done
The initial snapshot of the objects is not kept
Flush (applying changes) is also not done at the end of the transaction
In fact, in read-only:
When data is read from the database, it is registered as read-only in the persistence context and Hibernate does not manage it.
Since Hibernate does not manage it, there will be no dirty checking operation either.
So at the time of commit, no update command is issued and the permissions value in the database remains the same as 1000.
From Spring's perspective, this is a performance optimization; because when you are fetching data for reading only and not intending to change it, there is no need for dirty checking or snapshots.
This saves memory and time.

In read/write transactions → dirty checking is enabled, snapshot is kept, changes are applied to commit.
In read-only transactions → dirty checking is disabled, snapshot is not kept, flush is not performed.
So if you are sure that you only want to read the data and not change it, be sure to use read-only to get better performance.
If you want, I can explain this text to you in a simpler or more concise way — tell me how I can help you.
